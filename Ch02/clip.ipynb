{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7ab27d-b948-4701-a583-c8f8314c1eb2",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "## Title: Match Images and Captions Using CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa750d0-356a-4080-ae88-2c1a4314898c",
   "metadata": {},
   "source": [
    "## 2.1 Downloading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddf2b1b-e87c-4376-9513-508b823aa863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.3.1\n",
      "  Using cached torch-2.3.1-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.3.1) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.3.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.3.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.3.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.3.1) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.3.1) (2025.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "Using cached torch-2.3.1-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.17.2 requires torch==2.2.2, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.3.1\n",
      "Requirement already satisfied: torchvision==0.17.2 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torchvision==0.17.2) (1.26.4)\n",
      "Collecting torch==2.2.2 (from torchvision==0.17.2)\n",
      "  Using cached torch-2.2.2-cp310-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torchvision==0.17.2) (11.1.0)\n",
      "Requirement already satisfied: filelock in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.2.2->torchvision==0.17.2) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.2.2->torchvision==0.17.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.2.2->torchvision==0.17.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.2.2->torchvision==0.17.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.2.2->torchvision==0.17.2) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch==2.2.2->torchvision==0.17.2) (2025.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from jinja2->torch==2.2.2->torchvision==0.17.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from sympy->torch==2.2.2->torchvision==0.17.2) (1.3.0)\n",
      "Using cached torch-2.2.2-cp310-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "Successfully installed torch-2.2.2\n",
      "Requirement already satisfied: pycocotools in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from pycocotools) (3.10.0)\n",
      "Requirement already satisfied: numpy in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from pycocotools) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
      "Requirement already satisfied: transformers in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: timm in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (1.0.14)\n",
      "Requirement already satisfied: torch in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from timm) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from timm) (0.17.2)\n",
      "Requirement already satisfied: pyyaml in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from timm) (0.29.0)\n",
      "Requirement already satisfied: safetensors in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from timm) (0.5.2)\n",
      "Requirement already satisfied: filelock in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface_hub->timm) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torch->timm) (3.1.5)\n",
      "Requirement already satisfied: numpy in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from torchvision->timm) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -U torch==2.3.1\n",
    "! pip3 install torchvision==0.17.2\n",
    "! pip3 install pycocotools\n",
    "! pip3 install transformers\n",
    "! pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6197e8-31af-46b6-bc69-9302f88c7ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajatgoel/Documents/Manning Book Multimodal AI/Book Git Repo/book-venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2dcce0e-6d97-41cc-89f2-6074ceddc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad4e998-a665-47af-93e1-a30343c93dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5534ef34-37e8-4b78-84b4-bf7bcb312d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_dir = '../../Personal Git Repo/data/train2014'\n",
    "val_dir = '../../Personal Git Repo/data/val2014'\n",
    "train_ann_file = '../../Personal Git Repo/data/annotations/captions_train2014.json'\n",
    "val_ann_file = '../../Personal Git Repo/data/annotations/captions_val2014.json'\n",
    "# Images are <class 'PIL.Image.Image'> before transformation\n",
    "train_data = datasets.CocoCaptions(root=train_dir, annFile=train_ann_file, transform=image_transform)\n",
    "val_data = datasets.CocoCaptions(root=val_dir, annFile=val_ann_file, transform=image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829382c2-2d4a-498d-b722-0139a4855ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  82783\n",
      "Image Size:  torch.Size([3, 224, 224])\n",
      "Image  <class 'torch.Tensor'>\n",
      "['A zebra grazing on lush green grass in a field.', 'Zebra reaching its head down to ground where grass is. ', 'The zebra is eating grass in the sun.', 'A lone zebra grazing in some green grass.', 'a Zebra grazing on grass in a green open field.']\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples: ', len(train_data))\n",
    "img, target = train_data[3] # load 4th sample\n",
    "\n",
    "print(\"Image Size: \", img.size())\n",
    "print(\"Image \", type(img))\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd44af9c-e0b6-4a4f-9876-64d15f6ef23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoCaptionsFlattened(torch.utils.data.Dataset):\n",
    "    def __init__(self, coco_captions):\n",
    "        self.coco_captions = coco_captions\n",
    "        print(\"Number of images:\", len(self.coco_captions))\n",
    "        caption_counts = [len(captions) for _, captions in coco_captions]\n",
    "        self.cumulative_counts = self._compute_cumulative_counts(caption_counts)\n",
    "        print(\"Number of image x caption pairs:\", self.cumulative_counts[-1])\n",
    "\n",
    "    def _compute_cumulative_counts(self, counts):\n",
    "        cumulative = [0]\n",
    "        for count in counts:\n",
    "            cumulative.append(cumulative[-1] + count)\n",
    "        return cumulative\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cumulative_counts[-1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Find the image index corresponding to the flattened caption index\n",
    "        image_idx = bisect.bisect_right(self.cumulative_counts, index) - 1\n",
    "        caption_idx = index - self.cumulative_counts[image_idx]\n",
    "        # print(index, image_idx, caption_idx)\n",
    "        image, captions = self.coco_captions[image_idx]\n",
    "        return image, captions[caption_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6b68e4-9181-480b-9e2e-72453ef91537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 82783\n",
      "Number of image x caption pairs: 414113\n"
     ]
    }
   ],
   "source": [
    "train_data_flattened = CocoCaptionsFlattened(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8977bc0-85ca-497c-909f-b46f856223e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 40504\n",
      "Number of image x caption pairs: 202654\n"
     ]
    }
   ],
   "source": [
    "val_data_flattened = CocoCaptionsFlattened(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96cc37e-fb63-410c-9a4c-eca197479140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size:  torch.Size([3, 224, 224])\n",
      "A flower vase is sitting on a porch stand.\n"
     ]
    }
   ],
   "source": [
    "img, caption = train_data_flattened[10] # load 4th sample\n",
    "\n",
    "print(\"Image Size: \", img.size())\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b800a88-c633-47a4-a25a-a307671c4da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414113\n",
      "202654\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_flattened))\n",
    "print(len(val_data_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4035d3dd-7abb-4e53-9a7e-c53d0c3f7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ef33e5-fea6-426a-a3b1-405f62e99c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_captions(captions):\n",
    "    tokenized_caption = tokenizer(captions, padding=True, truncation=True, max_length=200)\n",
    "    encoded_captions = {}\n",
    "    for k in tokenized_caption.keys():\n",
    "        encoded_captions[k] = [torch.tensor(value).to(device) for value in tokenized_caption[k]]\n",
    "    return encoded_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c195e9-350e-4d7e-b76d-3400febbd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # len batch = 32\n",
    "    images, captions = zip(*batch)\n",
    "    # len images = 32, len captions = 32\n",
    "\n",
    "    # Transfer data to appropriate device\n",
    "    images = [image.to(device) for image in images]\n",
    "    images_batch = torch.stack(images)\n",
    "    \n",
    "    captions_batch = encode_captions(captions)\n",
    "    for k in captions_batch.keys():\n",
    "        captions_batch[k] = torch.stack(captions_batch[k])\n",
    "    \n",
    "    return images_batch, captions_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9326575d-154a-4bec-ad65-59b6492e7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_data_flattened, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_data_flattened, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa066bc-585a-411d-8f38-e98d2a818e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "32\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "32\n",
      "32\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "## For debugging\n",
    "for batch in train_loader:\n",
    "    # Process the batch\n",
    "    # batch is a tuple of size 2, each elem in tuple has size 32 (batch size)\n",
    "    # first elem is a list of image tensors, second elem is a list of dicts (for encoded captions)\n",
    "    print(len(batch))\n",
    "    print(len(batch[0]))\n",
    "    print(type(batch[0]))\n",
    "    print(len(batch[1]))\n",
    "    print(len(batch[1]['input_ids']))\n",
    "    print(len(batch[1]['attention_mask']))\n",
    "    print(type(batch[1]['input_ids']))\n",
    "    print(type(batch[1]['attention_mask']))\n",
    "    break  # To get only one sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa8fa8-ed0b-4396-93d1-cfe56fc3405f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c06edd-ec66-4c41-8d14-661cd4a41699",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c515e1ef-a6bf-4eb3-a48d-1bf2a4fa1735",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f786715-a4dd-4ad0-ba79-34760ad43b10",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0abce1-a34c-45df-ac12-ee086e4a8586",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Book Virtual Env",
   "language": "python",
   "name": "book-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
